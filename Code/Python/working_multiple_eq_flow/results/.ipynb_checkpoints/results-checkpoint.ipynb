{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438dda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import scipy.integrate as integrate \n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.misc import derivative\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db4b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_path = '/Users/benseimon/Documents/Barca GSE/Studies/Term 2/Networks/Term Paper/Networks_Term_Paper/Code/Python/working_multiple_eq_flow/SiouxFalls/pytrans_working_multiple_eq_flow'\n",
    "classes_path = r'C:\\Users\\35387\\OneDrive\\Documents\\Networks\\New folder\\Networks_Term_Paper\\Code\\Python\\working_multiple_eq_flow\\SiouxFalls\\pytrans_working_multiple_eq_flow'\n",
    "os.chdir(classes_path)\n",
    "import Frank_Wolfe\n",
    "import TransportationNetworks as tn\n",
    "#import visualize_graph #not working for niamh\n",
    "import custom_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01fffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cities dictionary\n",
    "def make_dict(cities):\n",
    "    cities_dict = {}\n",
    "    for city in cities:\n",
    "        link_file_path = data_path + city + sep + city + '_net.tntp.txt'\n",
    "        node_file_path = data_path + city + sep + city +'_nodes.tntp.txt'\n",
    "        trip_file_path = data_path + city + sep + city + '_trips.tntp.txt'\n",
    "        cities_dict[city] = {}\n",
    "        to_add = {'link_file_path': link_file_path, 'node_file_path': node_file_path, 'trip_file_path': trip_file_path}\n",
    "        cities_dict[city]['file_paths'] = to_add \n",
    "    return cities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f5603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle path (best if local)\n",
    "path = r\"C:\\Users\\35387\\OneDrive\\Documents\\Networks\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea305d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SiouxFalls_dict.pickle', 'rb') as handle:\n",
    "    SiouxFalls_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1823b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "check = list(SiouxFalls_dict['SiouxFalls'].keys())\n",
    "check.remove('file_paths')\n",
    "check.remove('csv')\n",
    "print(check) #check to see if there's one None\n",
    "for i in check:\n",
    "    if SiouxFalls_dict['SiouxFalls']['csv'].shape[0] <= len(SiouxFalls_dict['SiouxFalls'][i]['network'].graph.edges):\n",
    "        print(True)\n",
    "#should only print one True i.e. only one full network - 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "29150c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking that every edge has been removed once\n",
    "pd.DataFrame(columns = ['init_node', 'term_node'])\n",
    "full_edge_list = list(SiouxFalls_dict['SiouxFalls']\n",
    "                               ['None']['fw_run'].graph.edges) \n",
    "full_edge_list = set(full_edge_list) #get a set of all edges\n",
    "len(full_edge_list) #looks right and adds up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271ed14",
   "metadata": {},
   "source": [
    "In the below cell I am getting the same two errors on repeat:\n",
    "1. key error ['fw_run']\n",
    "2. KeyError: ('13', '24') -> pops up if I change the in check to anything except check (eg. the set of edges, a list of them, a subset of the list) (list_edges = list(full_edge_list); list_edges[1:5])\n",
    "\n",
    "The only way it runs smoothly is to specify one thing in check. There are definetly more things to try out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fade51e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fw_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [133]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m removed_edges \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#create empty list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m check: \n\u001b[1;32m----> 4\u001b[0m     edge_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mSiouxFalls_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSiouxFalls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfw_run\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39medges) \u001b[38;5;66;03m#get the edge list for a run\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     edge_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(edge_list) \u001b[38;5;66;03m#make it a set\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     removed_edges\u001b[38;5;241m.\u001b[39mappend(full_edge_list\u001b[38;5;241m.\u001b[39mdifference(edge_list)) \u001b[38;5;66;03m#append the missing edge to the list\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fw_run'"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(columns = ['init_node', 'term_node'])\n",
    "removed_edges = [] #create empty list\n",
    "for run in check: \n",
    "    edge_list = list(SiouxFalls_dict['SiouxFalls'][run]['fw_run'].graph.edges) #get the edge list for a run\n",
    "    edge_list = set(edge_list) #make it a set\n",
    "    removed_edges.append(full_edge_list.difference(edge_list)) #append the missing edge to the list\n",
    "removed_edges #print the list\n",
    "\n",
    "#removed_edges.difference(full_edge_list) #compare the two lists - should be no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dd25d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing one edge to compute the edge based measures\n",
    "remove_link = 0\n",
    "print(nx.density(SiouxFalls_dict['SiouxFalls'][str(remove_link)]['network'].graph))\n",
    "print(nx.diameter(SiouxFalls_dict['SiouxFalls'][str(remove_link)]['network'].graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5e346",
   "metadata": {},
   "source": [
    "I can't seem to get this quite right... from what I understand you need to get to the dropped link key in the city specific dictionary and then get the init node (origin) and term node (destination) from there.\n",
    "\n",
    "I actually assume I am just way off the mark in terms of initial steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "19eb983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['network', 'fw_run'])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to access one node \n",
    "one = SiouxFalls_dict['SiouxFalls'][str(1)]\n",
    "one.keys()\n",
    "#now network and fw_run objects are not subscriptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9679e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a cost calculating function to put in the loop\n",
    "#t(x)=t0[1+α(x/c)β]\n",
    "\n",
    "alpha = 0.15\n",
    "beta = 4\n",
    "capacity = capacity #getting this will follow same logic as node I think\n",
    "t0 = \n",
    "x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "de0f11ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Sioux Falls only version to then extrapolate up\n",
    "\n",
    "    #but what to pass to the function?\n",
    "        #the city, \n",
    "        \n",
    "        \n",
    "        # I wonder where it would be computationally less expensive to store the graph in the function \n",
    "        #eg. graph = SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph\n",
    "\n",
    "def get_results():\n",
    "    results_list = [] \n",
    "\n",
    "#Edge based measures\n",
    "    for link_to_remove in links:\n",
    "        \n",
    "\n",
    "        #density\n",
    "        density = []\n",
    "        density_i = nx.density(SiouxFalls_dict['SiouxFalls'][str(link_to_remove)]['network'].graph)\n",
    "        density.append(density_i)\n",
    "\n",
    "        #diameter\n",
    "        diameter = []\n",
    "        diameter_i = nx.diameter(SiouxFalls_dict['SiouxFalls'][str(link_to_remove)]['network'].graph)\n",
    "        diameter.append(diameter_i)\n",
    "\n",
    "#Node Based measures\n",
    "\n",
    "#origin nodes\n",
    "    for node in origin_nodes:\n",
    "        \n",
    "        #betweeness origin\n",
    "        betweeness_origin = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector origin\n",
    "        eigen_origin = []\n",
    "        eigen_origin_i = eigenvector_centrality(G, max_iter=100, tol=1e-06, nstart=None, weight=None)\n",
    "        eigen_origin.append(eigen_origin_i)\n",
    "        \n",
    "\n",
    "#destination nodes\n",
    "    for node in destination_nodes:\n",
    "        \n",
    "        #betweeness destination\n",
    "        betweeness_destination = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector destination\n",
    "        eigen_dest = []\n",
    "        eigen_dest_i = eigenvector_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph)\n",
    "        eigen_dest.append(eigen_dest_i)\n",
    "\n",
    "#Other based\n",
    "\n",
    "    #flow - from initial trips file i think \n",
    "    \n",
    "\n",
    "    #cost - will need to compute -> I think define function outside this function with alpha and beta set\n",
    "\n",
    "    results_list = results_list.append({ \n",
    "            'removed_link': link_to_remove, \n",
    "            'diameter': diameter,\n",
    "            'density': density,        \n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "print(results_df) #return was kicking off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31418ef",
   "metadata": {},
   "source": [
    "This is your version Ben, I just changed it because thought getting it to work for one was the best place to start, plus cities dict was not established in this notebook when I started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66110981",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cities_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#density\u001b[39;00m\n\u001b[0;32m     17\u001b[0m density \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 18\u001b[0m density \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mdensity(\u001b[43mcities_dict\u001b[49m[city][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#diameter\u001b[39;00m\n\u001b[0;32m     21\u001b[0m diameter \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cities_dict' is not defined"
     ]
    }
   ],
   "source": [
    "## for below analysis, remember that the removed_link = 1 means the last row in the trip file is removed. \n",
    "# Removed_link = 2 means the second last row is removed, and so on.\n",
    "# You can use this for the mapping from fw eq flow results to the csv/dataframe.\n",
    "\n",
    "#note that a set object is not subsettable so I converted to a list... not sure if this was the best call\n",
    "\n",
    "for city in cities_dict:\n",
    "    \n",
    "for link_to_removed in list_edges:\n",
    "\n",
    "    link_to_removed = i \n",
    "\n",
    "    #density\n",
    "    density = []\n",
    "    density = nx.density(cities_dict[city][i]['network'].graph)\n",
    "\n",
    "    #diameter\n",
    "    diameter = []\n",
    "    diameter = nx.diameter(cities_dict[city][i]['network'].graph)\n",
    "\n",
    "    #check this out for centrality https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "\n",
    "    #betweeness origin\n",
    "\n",
    "    #eigenvector origin\n",
    "    #eigenvector_centrality(cities_dict[city][str(remove_link)]['network'].graph)\n",
    "\n",
    "    #betweeness destination\n",
    "\n",
    "\n",
    "    #eigenvector destination\n",
    "\n",
    "    #flow - from initial trips file i think\n",
    "\n",
    "\n",
    "    #cost - will need to compute\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
