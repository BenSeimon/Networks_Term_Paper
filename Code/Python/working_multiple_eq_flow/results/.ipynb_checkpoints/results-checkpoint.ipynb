{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f25c770",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438dda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import scipy.integrate as integrate \n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.misc import derivative\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01fffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cities dictionary\n",
    "def make_dict(cities):\n",
    "    cities_dict = {}\n",
    "    for city in cities:\n",
    "        link_file_path = data_path + city + sep + city + '_net.tntp.txt'\n",
    "        node_file_path = data_path + city + sep + city +'_nodes.tntp.txt'\n",
    "        trip_file_path = data_path + city + sep + city + '_trips.tntp.txt'\n",
    "        cities_dict[city] = {}\n",
    "        to_add = {'link_file_path': link_file_path, 'node_file_path': node_file_path, 'trip_file_path': trip_file_path}\n",
    "        cities_dict[city]['file_paths'] = to_add \n",
    "    return cities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b9c56",
   "metadata": {},
   "source": [
    "# Path setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db4b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_path = '/Users/benseimon/Documents/Barca GSE/Studies/Term 2/Networks/Term Paper/Networks_Term_Paper/Code/Python/working_multiple_eq_flow/SiouxFalls/pytrans_working_multiple_eq_flow'\n",
    "os.chdir(classes_path)\n",
    "import Frank_Wolfe\n",
    "import TransportationNetworks as tn\n",
    "#import visualize_graph #not working for niamh\n",
    "import custom_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f5603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle path (best if local) download the dict from google drive\n",
    "path = '/Users/benseimon/Documents/Barca GSE/Studies/Term 2/Networks/Term Paper/pickles/'\n",
    "#path = r\"C:\\Users\\35387\\OneDrive\\Documents\\Networks\" #path to that file on your machine\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1392a",
   "metadata": {},
   "source": [
    "# Open pickle and run checks on the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea305d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SiouxFalls_dict.pickle', 'rb') as handle:\n",
    "    SiouxFalls_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1823b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#quick check\n",
    "check = list(SiouxFalls_dict['SiouxFalls'].keys())\n",
    "check.remove('file_paths')\n",
    "check.remove('csv')\n",
    "print(check) #check to see if there's one None\n",
    "for i in check:\n",
    "    if SiouxFalls_dict['SiouxFalls']['csv'].shape[0] <= len(SiouxFalls_dict['SiouxFalls'][i]['network'].graph.edges):\n",
    "        print(True)\n",
    "#should only print one True i.e. only one full network - 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a9fc3",
   "metadata": {},
   "source": [
    "# Create csv with equilibrium flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e63b5ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fw_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2g/qx04w6j525l446ptr2wd9w8w0000gn/T/ipykernel_69239/2923625454.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0meq_flow_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meq_flow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSiouxFalls_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SiouxFalls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fw_run'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0meq_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq_flow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minit_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fw_run'"
     ]
    }
   ],
   "source": [
    "results_csv = SiouxFalls_dict['SiouxFalls']['csv']\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['init node'] = SiouxFalls_dict['SiouxFalls']['csv']['init node'].astype(str)\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['term node'] = SiouxFalls_dict['SiouxFalls']['csv']['term node'].astype(str)\n",
    "links = list(SiouxFalls_dict['SiouxFalls'].keys())\n",
    "links.remove('file_paths')\n",
    "links.remove('csv')\n",
    "for link in links: #links should be max for whole dataframe\n",
    "    init_nodes = []\n",
    "    term_nodes = []\n",
    "    eq_flow_list = []\n",
    "    results_dict = {}\n",
    "    for (init_node, term_node, eq_flow) in SiouxFalls_dict['SiouxFalls'][link]['fw_run'].graph.edges(data=True):\n",
    "        eq_flow = eq_flow['object'].vol\n",
    "        init_nodes.append(init_node)\n",
    "        term_nodes.append(term_node)\n",
    "        eq_flow_list.append(eq_flow)\n",
    "        results_dict = {'init node': init_nodes, 'term node': term_nodes, 'eq_flow' : eq_flow_list}\n",
    "        results_df = pd.DataFrame(data=results_dict)\n",
    "    results_csv = results_csv.merge(results_df, how ='left', on = ['init node', 'term node'], suffixes = (None, '_removed_link')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bd60f",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46905029",
   "metadata": {},
   "source": [
    "## Dictionary access tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7733fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the graph on which the Frank Wolfe was computed\n",
    "chosen_link = '1'\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph #this is now like any digraph object that you can compute metrics on \n",
    "#e.g. nodes\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph.nodes\n",
    "#e.g. edges\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph.edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a4069",
   "metadata": {},
   "source": [
    "## Total cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9679e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a cost calculating function to put in the loop\n",
    "#t(x)=t0[1+α(x/c)β]\n",
    "\n",
    "alpha = 0.15\n",
    "beta = 4\n",
    "chosen_link = 1\n",
    "capacity = SiouxFalls_dict['SiouxFalls']['csv']['capacity'][chosen_link] #getting this will follow same logic as node I think\n",
    "t0 = \n",
    "x = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd9b66",
   "metadata": {},
   "source": [
    "## Network related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0096d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we are only looking at the original network, compute density and diameter for original network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(SiouxFalls_dict['SiouxFalls']['None']['fw_run'].graph)\n",
    "nx.diameter(SiouxFalls_dict['SiouxFalls']['None']['fw_rum'].graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744fc65",
   "metadata": {},
   "source": [
    "## Node related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068ecca",
   "metadata": {},
   "source": [
    "Centrality measures to compute are available here https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "Below is Niamh's first pass. This might be easier now that we have the csv but not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568247f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Based measures\n",
    "\n",
    "#origin nodes\n",
    "    for node in origin_nodes:\n",
    "        \n",
    "        #betweeness origin\n",
    "        betweeness_origin = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector origin\n",
    "        eigen_origin = []\n",
    "        eigen_origin_i = eigenvector_centrality(G, max_iter=100, tol=1e-06, nstart=None, weight=None)\n",
    "        eigen_origin.append(eigen_origin_i)\n",
    "        \n",
    "\n",
    "#destination nodes\n",
    "    for node in destination_nodes:\n",
    "        \n",
    "        #betweeness destination\n",
    "        betweeness_destination = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector destination\n",
    "        eigen_dest = []\n",
    "        eigen_dest_i = eigenvector_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph)\n",
    "        eigen_dest.append(eigen_dest_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f0a31",
   "metadata": {},
   "source": [
    "## Edge related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dd25d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1358695652173913\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#accessing one edge to compute the edge based measures\n",
    "remove_link = 0\n",
    "print(nx.density(SiouxFalls_dict['SiouxFalls'][str(remove_link)]['network'].graph))\n",
    "print(nx.diameter(SiouxFalls_dict['SiouxFalls'][str(remove_link)]['network'].graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5e346",
   "metadata": {},
   "source": [
    "I can't seem to get this quite right... from what I understand you need to get to the dropped link key in the city specific dictionary and then get the init node (origin) and term node (destination) from there.\n",
    "\n",
    "I actually assume I am just way off the mark in terms of initial steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to access one node \n",
    "SiouxFalls_dict['SiouxFalls'][str(1)]\n",
    "one.keys()\n",
    "#now network and fw_run objects are not subscriptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SiouxFalls_dict['SiouxFalls']['csv']['init node'] = SiouxFalls_dict['SiouxFalls']['csv']['init node'].astype(str)\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['term node'] = SiouxFalls_dict['SiouxFalls']['csv']['term node'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41384e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SiouxFalls_dict['SiouxFalls']['csv']\n",
    "test.merge(results_df, how = 'left', on = ['init node', 'term node'])['eq flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sioux Falls only version to then extrapolate up\n",
    "\n",
    "    #but what to pass to the function?\n",
    "        #the city, \n",
    "        \n",
    "        \n",
    "        # I wonder where it would be computationally less expensive to store the graph in the function \n",
    "        #eg. graph = SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph\n",
    "\n",
    "def get_results():\n",
    "    results_list = [] \n",
    "\n",
    "#Edge based measures\n",
    "    for link_to_remove in links:\n",
    "        #density\n",
    "        density = []\n",
    "        density_i = nx.density(SiouxFalls_dict['SiouxFalls'][str(link_to_remove)]['network'].graph)\n",
    "        density.append(density_i)\n",
    "\n",
    "        #diameter\n",
    "        diameter = []\n",
    "        diameter_i = nx.diameter(SiouxFalls_dict['SiouxFalls'][str(link_to_remove)]['network'].graph)\n",
    "        diameter.append(diameter_i)\n",
    "\n",
    "\n",
    "\n",
    "#Other based\n",
    "\n",
    "    #flow - from initial trips file i think \n",
    "    \n",
    "\n",
    "    #cost - will need to compute -> I think define function outside this function with alpha and beta set\n",
    "\n",
    "    results_list = results_list.append({ \n",
    "            'removed_link': link_to_remove, \n",
    "            'diameter': diameter,\n",
    "            'density': density,        \n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "print(results_df) #return was kicking off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31418ef",
   "metadata": {},
   "source": [
    "This is your version Ben, I just changed it because thought getting it to work for one was the best place to start, plus cities dict was not established in this notebook when I started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66110981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for below analysis, remember that the removed_link = 1 means the last row in the trip file is removed. \n",
    "# Removed_link = 2 means the second last row is removed, and so on.\n",
    "# You can use this for the mapping from fw eq flow results to the csv/dataframe.\n",
    "\n",
    "#note that a set object is not subsettable so I converted to a list... not sure if this was the best call\n",
    "\n",
    "for city in cities_dict:\n",
    "    \n",
    "for link_to_removed in list_edges:\n",
    "\n",
    "    link_to_removed = i \n",
    "\n",
    "    #density\n",
    "    density = []\n",
    "    density = nx.density(cities_dict[city][i]['network'].graph)\n",
    "\n",
    "    #diameter\n",
    "    diameter = []\n",
    "    diameter = nx.diameter(cities_dict[city][i]['network'].graph)\n",
    "\n",
    "    #check this out for centrality https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "\n",
    "    #betweeness origin\n",
    "\n",
    "    #eigenvector origin\n",
    "    #eigenvector_centrality(cities_dict[city][str(remove_link)]['network'].graph)\n",
    "\n",
    "    #betweeness destination\n",
    "\n",
    "\n",
    "    #eigenvector destination\n",
    "\n",
    "    #flow - from initial trips file i think\n",
    "\n",
    "\n",
    "    #cost - will need to compute\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
