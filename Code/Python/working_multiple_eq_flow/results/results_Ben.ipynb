{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f25c770",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d74a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "438dda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#import graphviz this didn't work I took it out for now\n",
    "import scipy.integrate as integrate \n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.misc import derivative\n",
    "from random import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01fffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cities dictionary\n",
    "def make_dict(cities):\n",
    "    cities_dict = {}\n",
    "    for city in cities:\n",
    "        link_file_path = data_path + city + sep + city + '_net.tntp.txt'\n",
    "        node_file_path = data_path + city + sep + city +'_nodes.tntp.txt'\n",
    "        trip_file_path = data_path + city + sep + city + '_trips.tntp.txt'\n",
    "        cities_dict[city] = {}\n",
    "        to_add = {'link_file_path': link_file_path, 'node_file_path': node_file_path, 'trip_file_path': trip_file_path}\n",
    "        cities_dict[city]['file_paths'] = to_add \n",
    "    return cities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b9c56",
   "metadata": {},
   "source": [
    "# Path setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db4b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_path = '/Users/joulevoelz/Documents/BSE/Networks/term_paper/Networks_Term_Paper/Code/Python/working_multiple_eq_flow/SiouxFalls/pytrans_working_multiple_eq_flow'\n",
    "os.chdir(classes_path)\n",
    "import Frank_Wolfe\n",
    "import TransportationNetworks as tn\n",
    "#import visualize_graph #not working for niamh\n",
    "import custom_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f5603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle path (best if local) download the dict from google drive\n",
    "path = '/Users/joulevoelz/Documents/BSE/Networks/pickle_files'\n",
    "#path = r\"C:\\Users\\35387\\OneDrive\\Documents\\Networks\" #path to that file on your machine\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1392a",
   "metadata": {},
   "source": [
    "# Open pickle and run checks on the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea305d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SiouxFalls_dict.pickle', 'rb') as handle:\n",
    "    SiouxFalls_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1823b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#quick check\n",
    "check = list(SiouxFalls_dict['SiouxFalls'].keys())\n",
    "check.remove('file_paths')\n",
    "check.remove('csv')\n",
    "print(check) #check to see if there's one None\n",
    "for i in check:\n",
    "    if SiouxFalls_dict['SiouxFalls']['csv'].shape[0] <= len(SiouxFalls_dict['SiouxFalls'][i]['network'].graph.edges):\n",
    "        print(True)\n",
    "#should only print one True i.e. only one full network - 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a9fc3",
   "metadata": {},
   "source": [
    "# Create csv with equilibrium flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cff95f",
   "metadata": {},
   "source": [
    "## Original flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ab879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below code appends the original flows\n",
    "##first you need to set the path to navigate to the trips file\n",
    "data_path = '/Users/joulevoelz/Documents/BSE/Networks/term_paper/Networks_Term_Paper/Data'\n",
    "cities = ['SiouxFalls']\n",
    "data_path = data_path \n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f7a2b",
   "metadata": {},
   "source": [
    "## Equilibrium flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63b5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below code appends the equilibrium flows for each of the runs\n",
    "results_csv = SiouxFalls_dict['SiouxFalls']['csv']\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['init node'] = SiouxFalls_dict['SiouxFalls']['csv']['init node'].astype(str)\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['term node'] = SiouxFalls_dict['SiouxFalls']['csv']['term node'].astype(str)\n",
    "links = list(SiouxFalls_dict['SiouxFalls'].keys())\n",
    "links.remove('file_paths')\n",
    "links.remove('csv')\n",
    "for link in links: #links should be max for whole dataframe\n",
    "    init_nodes = []\n",
    "    term_nodes = []\n",
    "    eq_flow_list = []\n",
    "    results_dict = {}\n",
    "    for (init_node, term_node, eq_flow) in SiouxFalls_dict['SiouxFalls'][link]['fw_run'].graph.edges(data=True):\n",
    "        eq_flow = eq_flow['object'].vol\n",
    "        init_nodes.append(init_node)\n",
    "        term_nodes.append(term_node)\n",
    "        eq_flow_list.append(eq_flow)\n",
    "        results_dict = {'init node': init_nodes, 'term node': term_nodes, link + '_removed': eq_flow_list}\n",
    "        results_df = pd.DataFrame(data=results_dict)\n",
    "    results_csv = results_csv.merge(results_df, how ='left', on = ['init node', 'term node'], suffixes = (None, None)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1faac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please run a check to see if each edge has been removed once. Can do this visually from the nas if you like\n",
    "results_csv.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bd60f",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b817f",
   "metadata": {},
   "source": [
    "Note that the csv is called results_csv if you need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "850aea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46905029",
   "metadata": {},
   "source": [
    "## Dictionary access tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7733fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the graph on which the Frank Wolfe was computed\n",
    "chosen_link = '1'\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph #this is now like any digraph object that you can compute metrics on \n",
    "#e.g. nodes\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph.nodes\n",
    "#e.g. edges\n",
    "SiouxFalls_dict['SiouxFalls'][chosen_link]['fw_run'].graph.edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a4069",
   "metadata": {},
   "source": [
    "## Total cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc9679e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a cost calculating function that returns the latency of an edge\n",
    "#based on Youn et al\n",
    "#t(x)=t0[1+α(x/c)^β]\n",
    "def latency(r_csv, edge, edge_removed):\n",
    "    \n",
    "    flow = 0\n",
    "    \n",
    "    #if the edge removed is a string\n",
    "    if type(edge_removed) == str:\n",
    "        flow = r_csv.at[edge,edge_removed]\n",
    "    else: #if the edge removed is  a number   \n",
    "        edge_removed_string = str(edge_removed) + \"_removed\"\n",
    "        #If the flow is NAN (the edge was removed), return 0\n",
    "        flow = r_csv.at[edge,edge_removed_string]\n",
    "    \n",
    "    if math.isnan(flow) == True:\n",
    "        return 0\n",
    "    \n",
    "    alpha = 0.2\n",
    "    beta = 4\n",
    "    t0 = r_csv.at[edge,\"free flow time\"]\n",
    "    capacity = r_csv.at[edge,\"capacity\"]\n",
    "    \n",
    "    return t0*(1 + alpha*(flow/capacity)**beta)\n",
    "\n",
    "# returns the total cost for equilibrium with a certain edge removed\n",
    "def total_cost(r_csv, edge_removed):\n",
    "    \n",
    "    ttl_cost = 0\n",
    "    for i in range(results_csv.shape[0]):\n",
    "        ttl_cost = ttl_cost + latency(r_csv,i,edge_removed)\n",
    "    \n",
    "    return ttl_cost\n",
    "\n",
    "#returns dataframe with total cost of flow for each link removed\n",
    "def total_cost_all(r_csv):\n",
    "    temp_df = pd.DataFrame(index = results_csv.index, columns = [\"ttl_cost_when_removed\"]) \n",
    "    for i in range(results_csv.shape[0]):\n",
    "        temp_df.at[i,\"ttl_cost_when_removed\"] = total_cost(r_csv,i)\n",
    "    \n",
    "    return temp_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5b81a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttl_cost_when_removed    791.047268\n",
       "dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test functions\n",
    "latency(results_csv,3,0)\n",
    "total_cost(results_csv,5)\n",
    "total_cost_all(results_csv).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a6531dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788.946063937142"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate equilibrium cost when none removed\n",
    "init_nodes = []\n",
    "term_nodes = []\n",
    "eq_flow_list = [] = []\n",
    "for (init_node, term_node, eq_flow) in SiouxFalls_dict['SiouxFalls']['None']['fw_run'].graph.edges(data=True):\n",
    "    eq_flow = eq_flow['object'].vol\n",
    "    init_nodes.append(init_node)\n",
    "    term_nodes.append(term_node)\n",
    "    eq_flow_list.append(eq_flow)\n",
    "    results_dict = {'init node': init_nodes, 'term node': term_nodes, 'eq_flow': eq_flow_list}\n",
    "none_df = pd.DataFrame(results_dict)\n",
    "none_df\n",
    "merged_df = pd.merge(none_df, results_csv)\n",
    "merged_df\n",
    "\n",
    "none_eq_cost = total_cost(merged_df, \"eq_flow\")\n",
    "none_eq_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd9b66",
   "metadata": {},
   "source": [
    "## Network related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a297b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0096d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we are only looking at the original network, compute density and diameter for original network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(SiouxFalls_dict['SiouxFalls']['None']['fw_run'].graph)\n",
    "nx.diameter(SiouxFalls_dict['SiouxFalls']['None']['fw_rum'].graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744fc65",
   "metadata": {},
   "source": [
    "## Node related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068ecca",
   "metadata": {},
   "source": [
    "Centrality measures to compute are available here https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "Below is Niamh's first pass. This might be easier now that we have the csv but not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568247f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Based measures\n",
    "\n",
    "#origin nodes\n",
    "    for node in origin_nodes:\n",
    "        \n",
    "        #betweeness origin\n",
    "        betweeness_origin = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector origin\n",
    "        eigen_origin = []\n",
    "        eigen_origin_i = eigenvector_centrality(G, max_iter=100, tol=1e-06, nstart=None, weight=None)\n",
    "        eigen_origin.append(eigen_origin_i)\n",
    "        \n",
    "\n",
    "#destination nodes\n",
    "    for node in destination_nodes:\n",
    "        \n",
    "        #betweeness destination\n",
    "        betweeness_destination = []\n",
    "        #betweenness_centrality(G, nodes)\n",
    "            #need to specify nodes in here\n",
    "        betweeness_origin_i = nx.betweenness_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph, NODES)\n",
    "        betweeness_origin.append(betweeness_origin_i)\n",
    "\n",
    "#how to specify nodes here?\n",
    "        #eigenvector destination\n",
    "        eigen_dest = []\n",
    "        eigen_dest_i = eigenvector_centrality(SiouxFalls_dict['SiouxFalls'][link_to_removed]['network'].graph)\n",
    "        eigen_dest.append(eigen_dest_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f0a31",
   "metadata": {},
   "source": [
    "## Edge related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SiouxFalls_dict['SiouxFalls']['csv']['init node'] = SiouxFalls_dict['SiouxFalls']['csv']['init node'].astype(str)\n",
    "SiouxFalls_dict['SiouxFalls']['csv']['term node'] = SiouxFalls_dict['SiouxFalls']['csv']['term node'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41384e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SiouxFalls_dict['SiouxFalls']['csv']\n",
    "test.merge(results_df, how = 'left', on = ['init node', 'term node'])['eq flow']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
